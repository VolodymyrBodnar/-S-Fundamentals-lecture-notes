
theme: white

# **Вступ**

У сучасному світі програмного забезпечення одна з основних проблем, з якими стикаються розробники та інженери DevOps, — це складність у розгортанні застосунків у різних середовищах. Наприклад, код, який ідеально працює на комп’ютері розробника, може не запускатися на сервері через відмінності в операційній системі, версіях бібліотек, конфігураціях середовища або інших залежностях. У традиційному підході до розгортання програмного забезпечення розробники часто мали вручну налаштовувати оточення, що призводило до великої кількості помилок та нестабільності.

Щоб вирішити ці проблеми, було запропоновано різні підходи до управління програмним середовищем. Спочатку розробники використовували звичайні скрипти для встановлення всіх необхідних залежностей, але це було ненадійно і складно в підтримці. Далі з’явилися системи управління пакетами, які спростили процес встановлення бібліотек, але все ще не вирішували проблему сумісності різних середовищ.

Віртуальні машини стали першим серйозним рішенням для цієї проблеми. Вони дозволяють створювати повністю ізольовані середовища, які можуть бути ідентичними як на комп’ютері розробника, так і на сервері. Віртуалізація дозволила запускати різні операційні системи на одному фізичному пристрої, що значно покращило контроль за оточенням. Проте віртуальні машини мали свої обмеження: вони вимагали значних апаратних ресурсів, були повільними при запуску і складними в управлінні при роботі з великою кількістю екземплярів.

Згодом була запропонована концепція контейнеризації, яка дозволяла запускати застосунки в ізольованих контейнерах, але без створення повноцінних віртуальних машин. Контейнеризація використовує ядро операційної системи спільно для всіх контейнерів, що значно зменшує витрати ресурсів і робить процес розгортання швидшим і простішим. Однією з ключових технологій, яка зробила контейнеризацію популярною і масовою, став Docker.

Docker дозволяє упакувати застосунок разом із усіма його залежностями в стандартний контейнер, який може бути запущений на будь-якій машині з встановленим Docker Engine. Це зробило процес розгортання передбачуваним і стабільним. Крім того, контейнери можуть легко масштабуватися, що особливо важливо для сучасних розподілених систем і мікросервісної архітектури.

Щоб ефективно працювати з Docker, потрібно розуміти основні принципи віртуалізації та контейнеризації, а також знати, як працює Docker і які можливості надає Docker Compose для управління складними багатоконтейнерними застосунками. У цій лекції ми розглянемо ці технології, їх переваги та способи використання на практиці.

# **Віртуальні машини (VM)**

## **Що таке віртуальна машина і навіщо вона потрібна?**

Віртуальна машина (VM, Virtual Machine) — це програмне середовище, яке імітує роботу фізичного комп’ютера. Вона дозволяє запускати операційну систему та програми так, наче вони працюють на реальному "залізі", хоча насправді виконуються всередині іншого програмного середовища. Віртуальні машини стали популярним рішенням для ізоляції середовища виконання, тестування програмного забезпечення, оптимізації використання серверних ресурсів та запуску додатків у різних операційних системах без потреби в додатковому обладнанні.

Головна ідея віртуалізації полягає в тому, що на одному фізичному сервері можна запустити кілька незалежних операційних систем. Це дозволяє більш ефективно використовувати ресурси та спрощує адміністрування великих інфраструктур. Замість того, щоб мати кілька окремих серверів для різних середовищ (наприклад, розробки, тестування та продакшну), можна розмістити всі ці середовища у віртуальних машинах на одному сервері.

## **Як працює віртуалізація?**

Віртуалізація базується на програмному забезпеченні, яке називається гіпервізором (hypervisor). Гіпервізор створює і управляє віртуальними машинами, розподіляючи між ними ресурси фізичного хоста, такі як процесор, оперативна пам’ять, дисковий простір і мережеві адаптери. Віртуальна машина отримує власну частину цих ресурсів, що дозволяє їй працювати незалежно від інших ВМ.

Гіпервізори бувають двох типів:

1. **Гіпервізори першого типу (bare-metal)** працюють безпосередньо на фізичному обладнанні, без потреби в базовій операційній системі. Вони забезпечують кращу продуктивність та ефективніше використовують ресурси. Прикладами таких гіпервізорів є VMware ESXi, Microsoft Hyper-V, KVM.
2. **Гіпервізори другого типу (hosted)** працюють як додаток на вже встановленій операційній системі. Вони простіші у встановленні та налаштуванні, але мають додатковий рівень накладних витрат через роботу поверх ОС хоста. Прикладами є VirtualBox, VMware Workstation, Parallels Desktop.

## **Переваги віртуальних машин**

Однією з головних переваг віртуальних машин є ізоляція середовища. Кожна ВМ працює незалежно, тому збої або зміни в одній віртуальній машині не впливають на інші. Це дозволяє безпечно тестувати нове програмне забезпечення або розгортати різні застосунки без ризику порушити роботу всієї системи.

Ще одна перевага — можливість запускати різні операційні системи на одному фізичному сервері. Наприклад, на одному комп’ютері можна одночасно мати Windows, Linux та macOS, кожна з яких працюватиме у власній ВМ. Це особливо корисно для розробників, яким потрібно тестувати програмне забезпечення на різних платформах.

Віртуалізація також значно спрощує масштабування інфраструктури. Якщо потрібно більше ресурсів, можна просто створити нову віртуальну машину або збільшити доступні ресурси для існуючих ВМ без потреби у фізичному розширенні серверного парку.

## **Недоліки віртуальних машин**

Попри всі переваги, віртуальні машини мають суттєві недоліки. Основним з них є велика витрата ресурсів. Кожна ВМ має власну операційну систему, що означає, що значна частина пам’яті, процесорної потужності та дискового простору витрачається на обслуговування ОС, а не на виконання корисних обчислень. Це особливо проблематично, коли потрібно запускати десятки чи сотні ВМ на одному сервері.

Ще один недолік — швидкість запуску. Віртуальна машина завантажується так само, як звичайний комп’ютер: спочатку ініціалізується BIOS, потім завантажується ядро ОС, запускаються всі необхідні сервіси. Це може займати кілька хвилин, що значно довше порівняно з контейнеризацією, де запуск контейнера триває секунди.

Крім того, віртуальні машини складніші в управлінні, особливо коли їхня кількість зростає. Автоматизація розгортання, оновлення та моніторингу ВМ потребує додаткових інструментів, таких як Ansible, Terraform або спеціальні рішення для управління хмарною інфраструктурою.

## **Приклади використання віртуальних машин**

Віртуальні машини широко використовуються у різних сферах. Наприклад, у великих компаніях вони застосовуються для створення серверних ферм, де на одному фізичному сервері працює кілька ізольованих середовищ для різних команд або проєктів.

В тестуванні програмного забезпечення ВМ дозволяють створювати різні конфігурації операційних систем і перевіряти сумісність застосунків. Розробники можуть легко відтворювати оточення користувача та відлагоджувати помилки, які виникають лише в певних умовах.

Ще один важливий сценарій використання віртуальних машин — це кібербезпека. Оскільки ВМ ізольовані від основної системи, вони можуть використовуватися для аналізу вірусів, тестування вразливостей та запуску потенційно небезпечного коду без ризику для основного комп’ютера.



# **Контейнеризація vs Віртуалізація**

## **Що таке контейнеризація?**

Контейнеризація — це технологія, яка дозволяє запускати застосунки в ізольованих середовищах, що називаються контейнерами. Контейнер містить усі необхідні залежності, бібліотеки та конфігурації, щоб програма працювала однаково на будь-якому пристрої чи сервері. Головною відмінністю контейнерів від віртуальних машин є те, що вони використовують ядро хостової операційної системи, а не запускають власну ОС. Це робить їх легшими, швидшими та ефективнішими в порівнянні з класичними віртуальними машинами.

Уявімо класичну проблему розробника: його застосунок чудово працює на локальному комп’ютері, але після розгортання на сервері виникають помилки. Причиною може бути інша версія бібліотек або конфігурації операційної системи. Контейнеризація розв’язує цю проблему, гарантуючи, що застосунок завжди працюватиме в однаковому середовищі, незалежно від того, де він запущений.

## **Ключові принципи контейнеризації**

Головна ідея контейнеризації полягає в тому, що кожен контейнер працює як окремий процес, ізольований від інших процесів на сервері. На відміну від віртуальних машин, контейнер не потребує окремої копії операційної системи, а використовує ядро хостової ОС.

Ізоляція контейнерів реалізується за допомогою таких технологій, як **Linux Namespaces** і **Control Groups (cgroups)**.

- **Namespaces** гарантують, що кожен контейнер має власний простір імен для процесів, мережі, файлової системи тощо. Завдяки цьому процеси всередині контейнера не бачать процесів інших контейнерів.
- **Cgroups** обмежують ресурси, які контейнер може використовувати (процесорний час, пам’ять, мережеву пропускну здатність). Це дозволяє уникнути ситуації, коли один контейнер забирає всі ресурси системи.

Контейнери також мають власні файлові системи, які базуються на шаруватих образах (image layers). Це означає, що кілька контейнерів можуть розділяти спільні базові шари образу, що значно економить дисковий простір.
#### **Linux Namespaces: Як працює ізоляція контейнерів**


Linux Namespaces є фундаментальним механізмом ядра Linux, який лежить в основі контейнеризації. Вони дозволяють створити для кожного процесу (або групи процесів, як у випадку контейнерів) власне, ізольоване середовище, у якому цей процес "бачить" лише певну частину системних ресурсів, а інші системні ресурси йому невидимі або недоступні. Саме завдяки Namespaces контейнери можуть працювати незалежно один від одного та від основної операційної системи, створюючи ілюзію окремого хоста для кожного контейнера.

Кожен контейнер отримує власний простір імен для ключових ресурсів, що запобігає конфліктам між процесами та гарантує безпеку і стабільність роботи. Розглянемо кожен з основних типів Namespaces детальніше:

### 1. PID (Process ID) Namespace

- **Призначення:** Ізолює ідентифікатори процесів (PID).
- **Як це працює:** Усередині PID Namespace кожен контейнер має свою власну нумерацію процесів, яка починається з PID 1. Цей процес з PID 1 у контейнері зазвичай є основним процесом, що запускає ваш застосунок. Процеси всередині одного контейнера "бачать" лише процеси, що належать до їхнього власного PID Namespace, і не мають доступу до процесів, які працюють за його межами на хостовій системі або в інших контейнерах. Це запобігає випадковому або зловмисному впливу одного контейнера на процеси іншого.
### 2. Mount Namespace

- **Призначення:** Дозволяє кожному контейнеру мати власну, незалежну файлову систему
- **Як це працює:** Коли створюється Mount Namespace, точка монтування (root filesystem) для нового простору імен може бути змінена, не впливаючи на файлову систему хоста або інших контейнерів. Це означає, що контейнер може монтувати або розмонтовувати власні диски та директорії незалежно від інших. Наприклад, ви можете оновити бібліотеку в одному контейнері, не впливаючи на версії тієї ж бібліотеки в іншому контейнері або на хості. Це також забезпечує ізоляцію даних і конфігурацій.

### 3. Network Namespace

- **Призначення:** Ізолює мережеві інтерфейси, маршрутизацію, правила брандмауера та таблиці IP-адрес.
- **Як це працює:** Кожен Network Namespace має власний набір мережевих пристроїв, таблиць маршрутизації, IP-адрес та портів. Це дозволяє контейнерам мати власні IP-адреси, які можуть бути ідентичними в різних контейнерах, не викликаючи конфліктів на хості. Контейнери можуть спілкуватися між собою через віртуальні мережеві інтерфейси (наприклад, Veth pairs) або через мережевий міст (bridge), створюваний Docker. Це забезпечує повну мережеву ізоляцію та дозволяє уникнути конфліктів портів.

### 4. UTS (Unix Timesharing System) Namespace

- **Призначення:** Дозволяє контейнеру мати власне ім'я хоста (hostname) та доменне ім'я.
- **Як це працює:** Коли ви заходите в контейнер і виконуєте команду `hostname`, ви побачите ім'я хоста, яке було призначено цьому конкретному контейнеру, а не ім'я хоста базової операційної системи. Це корисно для ідентифікації та конфігурації сервісів всередині контейнера.

### 5. IPC (Interprocess Communication) Namespace

- **Призначення:** Ізолює міжпроцесну взаємодію (IPC).
- **Як це працює:** Це включає такі механізми, як семафори, черги повідомлень та спільна пам'ять (shared memory). Ізоляція IPC гарантує, що процеси в одному контейнері не можуть випадково або навмисно використовувати або втручатися в пам'ять чи канали IPC інших процесів на хості або в інших контейнерах. Це критично важливо для безпеки та стабільності розподілених систем.

### 6. User Namespace

- **Призначення:** Дає змогу контейнерам працювати від імені некореневих користувачів, покращуючи безпеку.
- **Як це працює:** User Namespace дозволяє відображати ідентифікатори користувачів (UID) та груп (GID) всередині контейнера на інші UID/GID на хостовій системі. Наприклад, `root` користувач всередині контейнера може бути відображений на непривілейованого користувача на хості. Це значно підвищує безпеку, оскільки навіть якщо зловмисник отримає root-доступ всередині контейнера, ці привілеї не будуть перенесені на хостову систему.


## **Головні відмінності між контейнерами і віртуальними машинами**

Віртуальні машини і контейнери розв’язують схожі завдання — створення ізольованих середовищ для застосунків. Однак вони працюють за принципово різними підходами.

### 1. **Архітектура**

Віртуальні машини містять повну операційну систему, включаючи власне ядро. Вони використовують гіпервізор, який керує створенням та виконанням ВМ. Контейнери, навпаки, використовують ядро хостової ОС, а кожен контейнер працює у вигляді окремого процесу на сервері.

### 2. **Швидкість запуску**

Запуск віртуальної машини може займати кілька хвилин, оскільки потрібно завантажити ОС, ініціалізувати драйвери, мережу та інші системні сервіси. Контейнер запускається майже миттєво, оскільки це лише процес, що працює в уже запущеній ОС.

### 3. **Використання ресурсів**

Віртуальна машина займає більше місця на диску та використовує більше оперативної пам’яті, оскільки кожна ВМ має власне ядро ОС. Контейнери легші, оскільки вони спільно використовують ядро хостової ОС. Наприклад, якщо кожна віртуальна машина займає кілька гігабайтів, то контейнер може важити лише кілька сотень мегабайтів або навіть менше.

### 4. **Масштабованість**

Через свою легковагість контейнери набагато легше масштабувати. На одному сервері можна запускати десятки або навіть сотні контейнерів, тоді як кількість віртуальних машин обмежена через значні накладні витрати.

### 5. **Портативність**

Контейнери створюють однакове середовище для виконання застосунку, що робить їх дуже зручними для розгортання. Один і той самий контейнер можна запускати на локальному комп’ютері, тестовому сервері або в хмарному середовищі без змін у конфігурації. Віртуальні машини менш портативні, оскільки залежні від гіпервізора та конфігурації серверів.

## **Приклади використання контейнерів**

Контейнеризація використовується у багатьох сценаріях, де важливо забезпечити швидке, передбачуване та ефективне розгортання застосунків.

**1. Хмарні обчислення та мікросервіси**  
Сучасні хмарні платформи, такі як AWS, Google Cloud, Azure, активно використовують контейнери для розгортання мікросервісної архітектури. Кожен мікросервіс працює у власному контейнері, що дозволяє незалежно оновлювати та масштабувати окремі частини системи.

**2. CI/CD (безперервна інтеграція та розгортання)**  
Контейнери спрощують процес тестування та розгортання програмного забезпечення. Наприклад, у процесі CI/CD кожен етап може виконуватися в ізольованому контейнері, гарантуючи стабільність і відсутність конфліктів між різними середовищами.

**3. Великий бізнес та ентерпрайз рішення**  
Компанії використовують контейнери для створення передбачуваного середовища для своїх застосунків. Наприклад, банки, які мають десятки різних сервісів, можуть легко розгорнути кожен із них у контейнерах, забезпечуючи стабільність і безпеку.

**4. Обчислювальні кластери та наукові дослідження**  
У сфері машинного навчання та обчислювальних досліджень контейнеризація використовується для створення передбачуваних середовищ для запуску моделей та аналізу великих обсягів даних. Наприклад, контейнер із попередньо налаштованими бібліотеками TensorFlow або PyTorch дозволяє легко розгорнути середовище для тренування нейромереж.

# Docker

## **Що таке Docker і чому він став стандартом?**

Docker — це платформа для контейнеризації, яка дозволяє розробникам створювати, запускати та керувати контейнерами у спрощений і стандартизований спосіб. Його основна ідея полягає в тому, що розробник може "запакувати" застосунок разом із усіма його залежностями в контейнер, який потім можна запускати на будь-якому пристрої чи сервері, де встановлений Docker Engine.

Раніше, перед Docker, розгортання застосунків у різних середовищах часто спричиняло проблеми через розбіжності у версіях бібліотек або конфігураціях ОС. Docker дозволив позбутися цього завдяки використанню стандартизованих контейнерних образів (images), які гарантують однакову роботу застосунку на будь-якому хості.

Docker набув популярності завдяки простоті використання та високій ефективності. Він усунув складності, які існували з класичними віртуальними машинами, і зробив контейнеризацію доступною широкому колу розробників. Сьогодні Docker широко використовується у всіх сферах IT — від веброзробки до хмарних обчислень і DevOps-процесів.

## **Основні компоненти Docker**

Docker складається з кількох ключових компонентів, кожен із яких виконує свою роль у процесі контейнеризації.

### **Docker Engine**

Це основний рушій, який відповідає за створення, управління та виконання контейнерів. Він працює як серверний процес (`dockerd`), який приймає команди від клієнта Docker CLI і керує контейнерами.

### **Docker CLI (Command-Line Interface)**

Це інструмент командного рядка, який дозволяє взаємодіяти з Docker Engine. Наприклад, команда `docker run` використовується для запуску контейнера, а `docker ps` — для перегляду активних контейнерів.

### **Docker Image (Образи)**

Образ — це шаблон, який містить все необхідне для роботи контейнера: операційну систему, бібліотеки, залежності та сам застосунок. Образи створюються на основі `Dockerfile` і можуть бути збережені в реєстрах, таких як **Docker Hub**.

### **Docker Container (Контейнери)**

Контейнер — це запущений екземпляр образу. Він працює ізольовано від інших процесів у системі та може мати власні налаштування мережі, файлової системи та ресурсів.

### **Docker Hub та інші реєстри образів**

Docker Hub — це централізоване сховище, де можна знайти готові образи для різних застосунків. Окрім Docker Hub, існують приватні реєстри, такі як **GitHub Container Registry, AWS ECR, Google Container Registry**, які компанії використовують для зберігання власних контейнерних образів.

## **Як працює Docker?**

Процес роботи з Docker можна розділити на кілька основних етапів:

1. **Створення `Dockerfile`**  
    У цьому файлі описуються всі інструкції для створення образу, наприклад:
    
    ```dockerfile
    FROM python:3.11
    WORKDIR /app
    COPY . .
    RUN pip install -r requirements.txt
    CMD ["python", "app.py"]
    ```
    
    Тут:
    
    - **FROM python:3.11** — базовий образ із Python.
    - **WORKDIR /app** — встановлює робочу директорію.
    - **COPY . .** — копіює файли у контейнер.
    - **RUN pip install -r requirements.txt** — встановлює залежності.
    - **CMD ["python", "app.py"]** — вказує команду для запуску.
2. **Створення образу**  
    Використовується команда:
    
    ```
    docker build -t my-app .
    ```
    
    Це створить образ із назвою `my-app`.
    
3. **Запуск контейнера**
    
    ```
    docker run -d -p 8000:8000 my-app
    ```
    
    Тут `-d` означає запуск у фоновому режимі, а `-p 8000:8000` — проброс порту з контейнера на хост.
    
4. **Перегляд запущених контейнерів**
    
    ```
    docker ps
    ```
    
    Це покаже список активних контейнерів.
    
5. **Зупинка контейнера**
    
    ```
    docker stop container_id
    ```
    
    Контейнер можна зупинити за його `container_id` або `container_name`.
    


## Запуск Docker на Windows: Детальний Огляд

Docker Desktop на Windows дозволяє розробникам запускати Docker-контейнери, які зазвичай працюють на ядрі Linux, використовуючи технології віртуалізації. Це забезпечує безшовну інтеграцію та зручність роботи з контейнерами в середовищі Windows.

## Чому потрібна віртуалізація?

Контейнери Docker розроблені для роботи на Linux-ядрі. На відміну від віртуальних машин, які включають повну операційну систему, контейнери використовують ядро хостової операційної системи спільно для всіх контейнерів. Оскільки Windows має власне ядро, відмінне від Linux, для функціонування Docker Engine потрібен проміжний шар.

## Варіанти віртуалізації в Docker Desktop на Windows

Docker Desktop пропонує два основні механізми для віртуалізації, де працює Docker Engine:

### 1. Hyper-V (традиційний підхід)

* **Що це?** Hyper-V — це вбудована технологія віртуалізації від Microsoft, доступна у професійних і серверних версіях Windows.
* **Як це працює?** Коли встановлюється Docker Desktop і вибирається Hyper-V (або якщо WSL 2 не доступний), Docker Desktop створює легку віртуальну машину (VM) на базі Hyper-V. Ця VM працює на Linux-базі (наприклад, Alpine Linux або інший мінімалістичний дистрибутив), і саме всередині цієї VM запускається Docker Engine.
* **Переваги:** Довгий час це був стандартний спосіб запуску Docker на Windows, що забезпечував хорошу ізоляцію.
* **Недоліки:** VM Hyper-V може бути дещо важкою для ресурсів. Вона не завжди інтегрується так безшовно, як WSL 2, особливо у випадках, коли потрібно взаємодіяти з файловою системою Windows.

### 2. WSL 2 (Windows Subsystem for Linux 2) - рекомендований підхід

* **Що це?** WSL 2 — це покращена версія підсистеми Windows для Linux, яка використовує технологію віртуалізації для запуску повноцінного Linux-ядра всередині легкої VM. На відміну від WSL 1, яка була шаром сумісності, WSL 2 пропонує реальне Linux-ядро.
* **Як це працює?** Коли встановлюється Docker Desktop і активується інтеграція з WSL 2, Docker Engine запускається безпосередньо всередині дистрибутива WSL 2 (наприклад, Ubuntu). Docker Desktop використовує переваги архітектури WSL 2 для більш ефективної роботи. Файлова система Windows інтегрується з WSL 2 швидше, ніж з Hyper-V VM.
* **Переваги:**
    * **Вища продуктивність файлової системи:** Одна з найбільших переваг WSL 2, особливо коли Docker-проєкти знаходяться у файловій системі Windows.
    * **Краща інтеграція:** Більш плавна інтеграція між Windows і Linux середовищами.
    * **Менше споживання ресурсів:** WSL 2 є легшою віртуальною машиною порівняно з повноцінною Hyper-V VM.
    * **Зручність використання:** Можливість використовувати Linux-інструменти та середовища розробки безпосередньо з Windows.
* **Вимоги:** Для використання WSL 2 потрібна Windows 10 версії 1903 або вище з оновленим ядром WSL.

## Як Docker дозволяє функціонувати як на Linux-системі?

Незалежно від обраної технології (Hyper-V чи WSL 2), Docker Engine працює в середовищі Linux. Це означає, що контейнери запускаються та взаємодіють з Linux-ядром так, як це відбувалося б на "рідній" Linux-машині. Docker Desktop абстрагує цю складність від користувача, дозволяючи взаємодіяти з Docker через знайомий інтерфейс командного рядка (Docker CLI) прямо з Windows.

Таким чином, Docker Desktop на Windows є мостом, який дозволяє розробляти та запускати Docker-контейнери, призначені для Linux, на вашій Windows-системі, використовуючи при цьому технології віртуалізації для створення необхідного Linux-середовища.

## Процес запуску Docker на Windows

1.  **Завантажте та встановіть Docker Desktop**: Завантажте інсталятор з офіційного веб-сайту Docker і дотримуйтесь вказівок для встановлення.
2.  **Запустіть Docker Desktop**: Після встановлення знайдіть "Docker Desktop" у меню "Пуск" і запустіть його. Docker Desktop зазвичай запускається автоматично при старті Windows.
3.  **Перевірте статус Docker Engine**: Коли Docker Desktop запущено, ви побачите іконку Docker у системному треї. Коли вона стане стабільною (зазвичай зеленою або синьою, залежно від версії), це означає, що Docker Engine працює.
4.  **Використовуйте Docker CLI**: Відкрийте командний рядок (CMD або PowerShell) або термінал Linux (якщо ви використовуєте WSL 2) і виконайте команди Docker.
    * `docker run hello-world` – ця команда завантажить тестовий образ `hello-world` і запустить його в контейнері, демонструючи, що Docker працює коректно.
    * `docker ps` – покаже список активних контейнерів.


# Запуск Docker на macOS: Детальний Огляд

Docker Desktop на macOS, подібно до версії для Windows, надає зручний спосіб запуску Docker-контейнерів, призначених для Linux, на вашій системі. Оскільки контейнери Docker вимагають Linux-ядра, Docker Desktop для macOS використовує технології віртуалізації для створення необхідного середовища.

## Як працює віртуалізація на macOS

На macOS Docker Desktop використовує **HyperKit** – легкий віртуалізаційний рушій, побудований на фреймворку **Hypervisor.framework** від Apple.

- **Hypervisor.framework** – це низькорівневий API, який дозволяє програмам створювати та контролювати віртуальні машини безпосередньо, без необхідності встановлювати сторонні гіпервізори, як-от VirtualBox або VMware.
- **HyperKit** використовує цей фреймворк для створення мінімалістичної Linux-віртуальної машини. Саме всередині цієї VM працює Docker Engine.
- Ця віртуальна машина є легкою та оптимізованою для інтеграції з macOS, що забезпечує швидкий запуск контейнерів та ефективне використання ресурсів.

## Процес запуску Docker на macOS

1. **Завантажте та встановіть Docker Desktop**: Завантажте інсталятор `.dmg` з офіційного веб-сайту Docker. Перетягніть іконку Docker Desktop до папки "Програми" (Applications).
2. **Запустіть Docker Desktop**: Знайдіть "Docker Desktop" у папці "Програми" або через Spotlight та запустіть його. Під час першого запуску Docker Desktop може запитати дозволи для встановлення необхідних компонентів та доступу до системних ресурсів.
3. **Перевірте статус Docker Engine**: Після запуску, іконка Docker з'явиться у рядку меню macOS (menubar). Коли вона стане стабільною, це означає, що Docker Engine запущено та готовий до роботи.
4. **Використовуйте Docker CLI**: Відкрийте термінал (наприклад, Terminal.app або iTerm2) і виконайте команди Docker.
    - `docker run hello-world` – ця команда завантажить тестовий образ `hello-world` і запустить його в контейнері, підтверджуючи коректну роботу Docker.
    - `docker ps` – покаже список активних контейнерів.

## Інтеграція файлової системи та мережі

Docker Desktop на macOS забезпечує безшовну інтеграцію між файловою системою вашого Mac та контейнерами. Ви можете легко монтувати локальні директорії у ваші контейнери (використовуючи `bind mounts`), а Docker Desktop керує мережевим з'єднанням, дозволяючи контейнерам спілкуватися між собою та з зовнішнім світом.

Таким чином, Docker Desktop на macOS надає повністю функціональне середовище для роботи з Docker-контейнерами, ефективно використовуючи вбудовані можливості віртуалізації macOS для запуску Linux-ядра, необхідного для Docker Engine.

# Podman: Альтернатива Docker та її переваги

Попри широке поширення Docker, особливо Docker Desktop для Windows та macOS, існують ситуації, коли розробники та компанії звертають увагу на альтернативні інструменти. Однією з найпопулярніших таких альтернатив є **Podman**.

## Що таке Podman?

Podman – це бездемонний (daemonless) інструмент для розробки, керування та запуску контейнерів та контейнерних образів OCI (Open Container Initiative). На відміну від Docker, Podman не використовує фоновий процес (демон) для управління контейнерами. Це означає, що Podman запускає контейнери безпосередньо як дочірні процеси поточного користувача, що підвищує безпеку, оскільки немає потреби в привілейованому демоні. Podman пропонує майже повну сумісність з командами Docker CLI, що робить перехід на нього відносно легким.

## Чому варто використовувати Podman? (Особливо у контексті ліцензування Docker Desktop)

Однією з ключових причин, чому Podman набуває популярності, є **зміни в ліцензійній політиці Docker Desktop**. Раніше Docker Desktop був повністю безкоштовним для всіх користувачів, але з 2021 року Docker змінила свою ліцензійну модель. Docker Desktop залишається безкоштовним для:

- Невеликих компаній (менше 250 співробітників **І** менше 10 мільйонів доларів річного доходу).
- Особистого використання.
- Освіти.
- Некомерційних організацій.

Однак, для **великих підприємств**, які перевищують зазначені ліміти, Docker Desktop вимагає платної підписки. Це змусило багато компаній шукати безкоштовні та відкриті альтернативи, і Podman став очевидним вибором.


# Розгорнутий розгляд Dockerfile
## **Що таке Dockerfile і навіщо він потрібен?**

`Dockerfile` — це текстовий файл, у якому містяться інструкції для створення образу Docker. Він дозволяє описати весь процес налаштування середовища для застосунку, включаючи вибір базової операційної системи, встановлення необхідних бібліотек, додавання файлів, налаштування змінних середовища та команду для запуску контейнера.

Головна перевага використання `Dockerfile` у тому, що цей файл є декларативним: він дозволяє відтворювати однакове середовище кожного разу, коли збирається контейнер. Це критично важливо для стабільної роботи застосунків у продакшн-середовищах.

## **Основна структура Dockerfile**

`Dockerfile` складається з набору інструкцій, які виконуються послідовно під час створення образу. Ось типовий приклад:

```dockerfile
# Вказуємо базовий образ
FROM python:3.11

# Встановлюємо робочу директорію всередині контейнера
WORKDIR /app

# Копіюємо файли проєкту
COPY . .

# Встановлюємо залежності
RUN pip install -r requirements.txt

# Визначаємо змінну середовища
ENV APP_ENV=production

# Визначаємо порт, який буде використовуватися
EXPOSE 8000

# Визначаємо команду для запуску застосунку
CMD ["python", "app.py"]
```

Тепер розглянемо кожну інструкцію детальніше.

---

## **Основні інструкції в Dockerfile**

### **1. FROM — вибір базового образу**

Інструкція `FROM` визначає, який образ буде використано як базовий для нашого контейнера.

```dockerfile
FROM python:3.11
```

Це означає, що наш контейнер буде побудований на основі образу `python:3.11`, який містить встановлений Python. Можна також використовувати мінімальні образи, наприклад, `alpine`, який значно легший:

```dockerfile
FROM python:3.11-alpine
```

### **2. WORKDIR — зміна робочої директорії**

`WORKDIR` встановлює робочу директорію, в якій будуть виконуватися всі наступні команди:

```dockerfile
WORKDIR /app
```

Це аналогічно виконанню `cd /app` перед кожною командою. Використання `WORKDIR` дозволяє уникнути зайвих команд `RUN cd ...`.

### **3. COPY та ADD — копіювання файлів у контейнер**

Інструкція `COPY` використовується для копіювання файлів із локального комп’ютера в контейнер.

```dockerfile
COPY . .
```

Ця команда копіює всі файли поточної директорії (`.`) у директорію `/app` всередині контейнера (оскільки раніше ми визначили `WORKDIR`).

Альтернативно, можна використовувати `ADD`, яка, окрім копіювання файлів, дозволяє розпаковувати `.tar.gz` архіви та завантажувати файли з URL.

```dockerfile
ADD my_archive.tar.gz /app/
```

У більшості випадків **краще використовувати `COPY`**, оскільки вона передбачуваніша.

### **4. RUN — виконання команд під час збірки образу**

`RUN` виконує команду під час створення образу. Найчастіше її використовують для встановлення залежностей:

```dockerfile
RUN pip install -r requirements.txt
```

Кожна команда `RUN` створює **новий шар у файловій системі**, тому варто об’єднувати кілька команд в одну, щоб зменшити кількість шарів та зберегти кеш.

```dockerfile
RUN apt-get update && apt-get install -y \
    curl \
    nano \
    git
```

### **5. ENV — змінні середовища**

Інструкція `ENV` встановлює змінні середовища всередині контейнера.

```dockerfile
ENV APP_ENV=production
```

Це дозволяє змінювати поведінку застосунку без редагування коду.

### **6. EXPOSE — вказання відкритих портів**

Інструкція `EXPOSE` вказує, які порти будуть відкриті для взаємодії з контейнером.

```dockerfile
EXPOSE 8000
```

Проте `EXPOSE` не відкриває порт автоматично — це лише документація для розробників. Щоб справді пробросити порт, треба запускати контейнер із флагом `-p`, наприклад:

```
docker run -p 8000:8000 my-app
```

### **7. CMD та ENTRYPOINT — команда для запуску контейнера**

`CMD` задає команду, яка виконується при запуску контейнера.

```dockerfile
CMD ["python", "app.py"]
```

На відміну від `RUN`, яка виконується при створенні образу, `CMD` виконується під час запуску контейнера.

Якщо потрібно передати аргументи командному рядку, краще використовувати `ENTRYPOINT`:

```dockerfile
ENTRYPOINT ["python", "app.py"]
```

Це дозволяє додавати параметри при запуску контейнера:

```
docker run my-app --debug
```

---

## **Шарова структура образу Docker**

Кожен образ Docker складається з **шарів** (layers), які формуються при виконанні кожної команди в `Dockerfile`.

### **Як працюють шари?**

1. Кожна команда в `Dockerfile` створює **новий шар у файловій системі**.
2. Docker використовує механізм **кешування**, щоб не будувати заново шари, які не змінилися.
3. При внесенні змін у `Dockerfile`, Docker **перебудовує тільки ті шари, які змінилися, і всі наступні шари будуть створені заново**.

Наприклад, розглянемо такий `Dockerfile`:

```dockerfile
FROM python:3.11
COPY . .
RUN pip install -r requirements.txt
CMD ["python", "app.py"]
```

Якщо змінити `requirements.txt`, команда `RUN pip install -r requirements.txt` виконається з нуля, а всі наступні шари (`CMD`) будуть теж перебудовані.

### **Що таке шар у Docker з точки зору файлової системи?**

Шар у Docker — це окремий набір файлів і змін, який додається до попередніх шарів, щоб утворити повну файлову систему контейнера. Уяви це як стопку прозорих плівок, де кожен шар додає або змінює файли, але при цьому не змінює попередні шари.

Базовий образ (`FROM ubuntu:22.04`) — це перший шар, який містить операційну систему. Коли ми додаємо команду `RUN apt-get install curl`, Docker створює новий шар, який додає всі нові файли, створені під час встановлення `curl`. Якщо ми копіюємо код (`COPY . /app`), це додає ще один шар, що містить лише файли, які ми скопіювали.

З точки зору файлової системи, Docker використовує спеціальні механізми (наприклад, **OverlayFS**), які дозволяють об’єднувати всі ці шари в один логічний каталог. Коли контейнер запускається, він отримує ще один шар для запису (Writable Layer), у який записуються всі зміни, зроблені під час роботи контейнера. Але самі шари образу залишаються незмінними.

Завдяки цьому, якщо ми створюємо новий контейнер на основі того ж образу, Docker не дублює всі файли, а використовує існуючі шари. Це економить місце і пришвидшує запуск контейнерів.

### **Як ефективно працювати з кешем?**

Щоб зменшити кількість перебудов, варто дотримуватися таких правил:

4. **Розміщувати змінні команди ближче до кінця**. Наприклад, якщо залежності рідко змінюються, але код оновлюється часто:
    
    ```dockerfile
    FROM python:3.11
    WORKDIR /app
    COPY requirements.txt requirements.txt
    RUN pip install -r requirements.txt
    COPY . .
    CMD ["python", "app.py"]
    ```
    
    Тут, якщо зміняться лише файли застосунку, але `requirements.txt` залишиться незмінним, Docker зможе використати кешований шар і не перевстановлювати залежності.
    
5. **Об’єднувати команди `RUN`**.
    
    ```dockerfile
    RUN apt-get update && apt-get install -y curl nano git && rm -rf /var/lib/apt/lists/*
    ```
    
    Це зменшує кількість шарів і покращує кешування.
    

---
### **Що таке базовий образ і навіщо він потрібен?**

Базовий образ (base image) — це початковий шар, на основі якого створюється контейнерний образ у Docker. Він містить мінімально необхідне середовище для роботи застосунку, включаючи операційну систему (або її частину), бібліотеки та інструменти.

Коли ми створюємо власний `Dockerfile`, у більшості випадків ми починаємо з вказання базового образу за допомогою інструкції `FROM`. Наприклад, якщо ми розробляємо застосунок на Python, то логічно використовувати офіційний образ Python:

```dockerfile
FROM python:3.11
```

Цей образ уже містить встановлений інтерпретатор Python, тому нам не потрібно самостійно налаштовувати середовище з нуля.

Якщо ми працюємо з вебсервером Nginx, ми можемо взяти офіційний базовий образ:

```dockerfile
FROM nginx:latest
```

Або, якщо хочемо максимального контролю над середовищем, можемо взяти мінімалістичний образ, наприклад, `alpine`:

```dockerfile
FROM alpine:latest
```

Такі образи дуже легкі (звичайний `alpine` важить всього ~5MB), що робить їх ідеальними для створення компактних контейнерів.

---

### **Як базові образи працюють "під капотом"?**

Базовий образ є першим шаром у файловій системі контейнера. Коли ми будуємо новий образ, Docker не створює весь файловий простір з нуля, а просто **бере вже існуючий базовий образ і додає поверх нього нові шари**. Це економить дисковий простір і пришвидшує процес збірки.

Наприклад, якщо ми створюємо образ із `FROM python:3.11`, Docker перевіряє, чи є цей образ у локальному кеші (`docker images`). Якщо ні, він завантажує його з Docker Hub або іншого реєстру (`docker pull`). Далі всі наступні команди (`RUN`, `COPY` тощо) додають нові шари поверх базового образу.

Ця шарувата структура дозволяє Docker ефективно використовувати кеш: якщо базовий образ не змінювався, його не потрібно завантажувати заново при кожній збірці.

Також ми можемо створити **власний базовий образ**. Наприклад, якщо нам потрібен кастомний мінімалістичний образ із певним набором інструментів, ми можемо створити його з нуля:

```dockerfile
FROM scratch
COPY my-binary /app/my-binary
CMD ["/app/my-binary"]
```

Образ `scratch` — це порожній образ, який не містить жодної файлової системи. Він використовується для створення ультралегких контейнерів, які містять лише один бінарний файл (наприклад, Golang-застосунки).

Таким чином, базовий образ є основою для всіх контейнерів. Використання офіційних базових образів дозволяє уникнути складного налаштування середовища, зекономити час і забезпечити стабільність у розгортанні застосунків. 🚀

# **Docker Compose: оркестрація багатоконтейнерних застосунків**

## **Що таке Docker Compose і навіщо він потрібен?**

Docker дозволяє легко запускати окремі контейнери, але що робити, якщо застосунок складається з кількох сервісів? Наприклад, типовий веб-застосунок може включати:

- бекенд (наприклад, Python або Node.js);
- базу даних (PostgreSQL, MySQL, MongoDB тощо);
- кеш (Redis, Memcached);
- фронтенд (React, Angular, Vue тощо);
- зворотний проксі (Nginx, Traefik).

У такому випадку запуск кожного контейнера окремо з купою `docker run -d ...` команд стає незручним. Тут на допомогу приходить **Docker Compose** — інструмент, який дозволяє описати всі контейнери та їхню конфігурацію в одному `docker-compose.yml` файлі й запускати їх одним рядком команди.

## **Як працює Docker Compose?**

Docker Compose використовує `.yml`-файл для опису конфігурації всіх сервісів у застосунку. У цьому файлі визначається, які образи використовувати, які змінні середовища передавати, як налаштувати мережу та зберігання даних.

Основні можливості Docker Compose:

1. **Запуск кількох контейнерів одночасно** — всі сервіси застосунку стартують командою `docker-compose up`.
2. **Автоматичне створення мережі** — всі сервіси взаємодіють між собою через створену Docker-мережу.
3. **Оголошення змінних середовища** — легко налаштовуються через `.env`-файл.
4. **Збереження даних між перезапусками** — автоматично створюються томи для баз даних та інших сервісів.
5. **Гнучке управління** — можна легко запускати, зупиняти та переглядати логи всіх контейнерів (`docker-compose logs`).

## **Приклад простого `docker-compose.yml`**

Ось приклад `docker-compose.yml` для вебзастосунку на Python + PostgreSQL:

```yaml
version: "3.9"

services:
  web:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgres://user:password@db:5432/mydb
    depends_on:
      - db

  db:
    image: postgres:15
    restart: always
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: mydb
    volumes:
      - pg_data:/var/lib/postgresql/data

volumes:
  pg_data:
```

### **Розбір цього файлу:**

6. `version: "3.9"` — вказує версію синтаксису Docker Compose.
7. `services:` — описує всі сервіси, які потрібно запустити.
8. `web:` — сервіс вебзастосунку.
    - `build: .` — вказує, що образ потрібно зібрати з `Dockerfile`.
    - `ports: "8000:8000"` — проброс порту.
    - `environment:` — задає змінні середовища.
    - `depends_on: - db` — гарантує, що контейнер `db` буде запущений перед `web`.
9. `db:` — сервіс бази даних.
    - `image: postgres:15` — бере готовий образ PostgreSQL.
    - `restart: always` — автоматично перезапускає контейнер у разі збою.
    - `volumes:` — вказує, що дані бази будуть зберігатися між перезапусками.
10. `volumes:` — створює віртуальний диск `pg_data`, який прив’язаний до `/var/lib/postgresql/data`.

## **Запуск Docker Compose**

Щоб запустити всі сервіси з `docker-compose.yml`, достатньо виконати:

```
docker-compose up -d
```

Флаг `-d` означає **запуск у фоновому режимі**. Якщо потрібно побачити логи, можна виконати:

```
docker-compose logs -f
```

Щоб зупинити всі сервіси:

```
docker-compose down
```

## **Переваги Docker Compose**

- **Спрощене управління контейнерами** — не потрібно вручну запускати кожен контейнер.
- **Консистентне середовище** — всі розробники використовують однаковий набір контейнерів.
- **Легка інтеграція з CI/CD** — можна автоматично запускати тести в контейнерах.
- **Збереження стану між перезапусками** — дані бази залишаються навіть після `docker-compose down`.


### **Docker Networking: Як контейнери спілкуються між собою **

#### **Як працює мережа в Docker?**

Docker має вбудовану систему керування мережею, яка дозволяє ізольованим контейнерам обмінюватися даними між собою та з зовнішнім світом. Уявіть, що кожен контейнер — це окремий комп'ютер, а Docker створює для них віртуальну локальну мережу.

Кожен контейнер у цій мережі отримує свою унікальну IP-адресу, але найголовніше — він отримує **DNS-ім'я**. Це дозволяє контейнерам легко "знаходити" один одного, звертаючись за простим іменем, а не за IP-адресою, яка може змінюватися.

---

#### **Керування та діагностика мереж**

Перш ніж заглиблюватися в типи мереж, важливо знати, як їх переглядати та аналізувати.

###### Перегляд списку мереж: `docker network ls`

Ця команда показує всі Docker-мережі, що існують на вашому комп'ютері. Виконавши її, ви побачите стандартний набір, а також мережі, створені `docker-compose` для ваших проєктів.

Bash

```
$ docker network ls
NETWORK ID     NAME                   DRIVER    SCOPE
a1b2c3d4e5f6   bridge                 bridge    local
g7h8i9j0k1l2   host                   host      local
m3n4o5p6q7r8   none                   none      local
p9o8i7u6y5t4   my_project_default     bridge    local
```

Тут `my_project_default` — це мережа, автоматично створена для проєкту `my_project`.

###### Детальна інформація про мережу: `docker network inspect`

Ця команда дозволяє "зазирнути" всередину конкретної мережі: подивитися її налаштування, діапазон IP-адрес та, найголовніше, які контейнери до неї підключені.

Bash

```
docker network inspect my_project_default
```

У виводі ви знайдете секцію `"Containers"`, де буде перераховано всі контейнери, підключені до цієї мережі, разом із їхніми іменами та внутрішніми IP-адресами. Це надзвичайно корисна команда для діагностики проблем зі з'єднанням.

---

## **Типи мереж у Docker**

Docker пропонує кілька типів (драйверів) мереж для різних сценаріїв.

##### 1. Bridge (за замовчуванням)

Це найпоширеніший тип. `Bridge`-мережа створює ізольований простір для контейнерів на одному хості.

- **Як це працює?** Docker створює віртуальну приватну мережу. Кожен контейнер отримує свою IP-адресу.
- **Важливо:** Коли ви використовуєте `docker-compose`, він створює **нову `bridge`-мережу** спеціально для вашого проєкту, ізолюючи його від інших.
- **Приклад створення вручну:**

  ```
  docker network create my_custom_network
  docker run -d --name backend --network my_custom_network python:3.11    
  ```

##### 2. Host (прямий доступ до мережі хоста)

У цьому режимі контейнер не має власної ізольованої мережі, а напряму використовує мережу вашого комп'ютера (хоста). Це дає вищу продуктивність, але втрачається головна перевага Docker — ізоляція.

Bash

```
docker run --network host -d nginx
```

Тепер Nginx буде доступний напряму за IP-адресою хоста, без прокидання портів.

##### 3. None (повна ізоляція)

Це "режим польоту" для контейнера. Він не має жодного мережевого підключення. Це корисно для виконання безпечних завдань, які не потребують доступу до мережі.

Bash

```
docker run --network none -d alpine
```

##### 4. Overlay (для контейнерів на різних хостах)

Цей тип мережі використовується в системах оркестрації (Docker Swarm, Kubernetes) і дозволяє контейнерам, що працюють на різних фізичних або віртуальних серверах, комунікувати між собою так, ніби вони знаходяться в одній локальній мережі.

---

## **Практика: Як контейнери спілкуються**

##### Зв'язок із зовнішнім світом: Прокидання портів (`-p`)

Щоб зробити сервіс у контейнері доступним ззовні (наприклад, з вашого браузера), потрібно "прокинути" порт з хост-машини на контейнер за допомогою прапора `-p` (`--publish`).

Bash

```
docker run -d -p 8080:80 nginx
```

Це означає: "Усі запити, що приходять на порт **8080** мого комп'ютера, перенаправляти на порт **80** всередині контейнера".

##### Зв'язок між контейнерами

Головне правило: **ніколи не використовуйте IP-адреси для з'єднання між контейнерами.** Замість цього завжди використовуйте **ім'я сервісу**, яке ви визначили в `docker-compose.yml`.

Docker має вбудовану систему DNS. Коли один контейнер намагається звернутися до іншого за іменем, Docker автоматично перетворює це ім'я на правильну внутрішню IP-адресу.

#### **Приклад на Python**

Уявімо, що у вас є сервіс `web` (Python) та сервіс `db` (PostgreSQL).

**`docker-compose.yml`**:

YAML

```
services:
  web:
    build: .
    environment:
      # Передаємо ім'я хоста бази даних у контейнер
      - DATABASE_HOST=db
    depends_on:
      - db

  db: # <-- Це ім'я сервісу
    image: postgres:15-alpine
```

**Код на Python (`web`)**:

Python

```
import os
import psycopg2

# Беремо ім'я хоста зі змінної середовища
db_host = os.getenv("DATABASE_HOST") # Тут буде "db"

# Python підключається до хоста 'db', а Docker сам знаходить його IP
connection = psycopg2.connect(
    host=db_host,
    database="mydb",
    user="user",
    password="password"
)
```

Завдяки вбудованому DNS, ваш Python-код успішно знаходить базу даних за іменем `db`.
## **Docker Volumes: Як зберігаються дані в контейнерах?**

## **Що таке Volumes у Docker і навіщо вони потрібні?**

За замовчуванням всі дані всередині контейнера зберігаються у його файловій системі. Проте, якщо контейнер буде видалений (`docker rm`), **всі його дані також зникнуть**. Щоб цього уникнути, Docker надає механізм **volumes**, який дозволяє зберігати дані **поза контейнером**, щоб вони не зникали між перезапусками.

---
## **Типи збереження даних у Docker**

### **1. Анонімні томи (Anonymous Volumes)**

Docker створює тимчасовий том, який існує лише доки контейнер не буде видалений.

```bash
docker run -d -v /data busybox
```

Тут `/data` буде збережене в анонімному томі, але якщо контейнер буде видалений, дані теж зникнуть.

---

### **2. Іменовані томи (Named Volumes)**

Це рекомендований спосіб збереження даних. Названі томи зберігаються незалежно від контейнера.

```bash
docker volume create my_data
docker run -d -v my_data:/app/data busybox
```

Тепер навіть після видалення контейнера дані залишаться.

---

### **3. Bind Mounts (Пряме підключення папок хоста)**

На відміну від томів, bind mounts підключають конкретну директорію хостової файлової системи до контейнера.

```bash
docker run -d -v /home/user/data:/app/data busybox
```

Тут `/home/user/data` буде відображене в контейнері як `/app/data`. Будь-які зміни в цій папці будуть відображатися як на хості, так і в контейнері.

---

## **Як керувати Volumes?**

### **Перегляд списку всіх томів**

```bash
docker volume ls
```

### **Видалення тома**

```bash
docker volume rm my_data
```

### **Приклад використання в Docker Compose**

```yaml
version: "3.9"

services:
  db:
    image: postgres:15
    volumes:
      - pg_data:/var/lib/postgresql/data

volumes:
  pg_data:
```

Цей том залишиться навіть після перезапуску контейнера.
